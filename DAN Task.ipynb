{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f9c64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d7074",
   "metadata": {},
   "source": [
    "# Deep Average Network –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d972fe",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–π –¥–æ–º–∞—à–∫–µ –º—ã –±—É–¥–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–≤–∏—Ç—ã –Ω–∞ 3 —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.  \n",
    "–í—ã –±—É–¥–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤, —Ç–∞–∫ —á—Ç–æ –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å [—Ç—É—Ç–æ—Ä–∏–∞–ª –ø–æ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é](https://github.com/BobaZooba/DeepNLP/blob/master/Tutorials/Word%20vectors%20%26%20Data%20Loading.ipynb).\n",
    "\n",
    "–ù–∞—à–∏ –∫–ª–∞—Å—Å—ã:  \n",
    "\n",
    "–ò–Ω–¥–µ–∫—Å | Sentiment  \n",
    "-- | --  \n",
    "0 | negative  \n",
    "1 | neutral  \n",
    "2 | positive  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55010212",
   "metadata": {},
   "source": [
    "–í–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç–∞–∫—É—é –º–æ–¥–µ–ª—å:\n",
    "![–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ DAN](https://www.researchgate.net/profile/Shervin-Minaee/publication/340523298/figure/fig1/AS:878252264550411@1586403065555/The-architecture-of-the-Deep-Average-Network-DAN-10.ppm)\n",
    "\n",
    "–ß—Ç–æ –æ–Ω–∞ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç:\n",
    "- –ú—ã –ø–æ–¥–∞–µ–º –≤ –Ω–µ–µ –∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤\n",
    "- –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤ –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "- –£—Å—Ä–µ–¥–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "- –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ `Multilayer Perceptron`\n",
    "\n",
    "–í —ç—Ç–æ–π –¥–æ–º–∞—à–∫–µ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç:\n",
    "- –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç—ã –≤ –º–∞—Ç—Ä–∏—Ü—ã —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "- –û–±—É—á–∏—Ç—å –µ–µ\n",
    "- –ü–æ–Ω—è—Ç—å —Ö–æ—Ä–æ—à–æ –ª–∏ –≤—ã —ç—Ç–æ —Å–¥–µ–ª–∞–ª–∏\n",
    "\n",
    "–≠—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–∞—è –º–æ–¥–µ–ª—å, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∞ –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏. –í –¥–∞–ª—å–Ω–µ–π—à–µ–º –Ω–∞ —Ä–∞–±–æ—Ç–µ —Å–æ–≤–µ—Ç—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–∫—É—é –º–æ–¥–µ–ª—å –∫–∞–∫ –±–µ–π–∑–ª–∞–π–Ω. –ò –≤ –∫–∞—á–µ—Å—Ç–≤–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–ª–æ–≤ –≤–∑—è—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –±–µ—Ä—Ç–∞/—Ä–æ–±–µ—Ä—Ç—ã/—Ç–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65faf753",
   "metadata": {},
   "source": [
    "## ü§ó Datasets\n",
    "–í —ç—Ç–æ–º —Ç—É—Ç–æ—Ä–∏–∞–ª–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [datasets](https://github.com/huggingface/datasets). –ú—ã –≤—Ä—è–¥ –ª–∏ –µ—â–µ –±—É–¥–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —ç—Ç–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π, —Ç–∞–∫ –∫–∞–∫ –Ω–∞–º –±—É–¥–µ—Ç –≤–∞–∂–Ω–æ —Å–∞–º–∏–º –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –í–æ-–ø–µ—Ä–≤—ã—Ö, –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –≤–æ-–≤—Ç–æ—Ä—ã—Ö, –∑–¥–µ—Å—å –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–µ–ø–ª–æ—Ö–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏. [–ó–¥–µ—Å—å](https://huggingface.co/datasets) –≤—ã —Å–º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤. –í–æ–∑–º–æ–∂–Ω–æ, –∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å –æ–Ω–∏ –≤–∞–º –ø—Ä–∏–≥–æ–¥—è—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927f02a",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤\n",
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ –∑–∞–≥—Ä—É–∑–∫–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞. –û–Ω–∞ –¥–æ–ª–∂–Ω–∞ –æ—Ç–¥–∞–≤–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å–ª–æ–≤ –∏ `np.array`\n",
    "–§–æ—Ä–º–∞—Ç —Å–ª–æ–≤–∞—Ä—è:\n",
    "```python\n",
    "{\n",
    "    'aabra': 0,\n",
    "    ...,\n",
    "    'mom': 6546,\n",
    "    ...\n",
    "    'xyz': 100355\n",
    "}\n",
    "```\n",
    "–§–æ—Ä–º–∞—Ç –º–∞—Ç—Ä–∏—Ü—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:\n",
    "```python\n",
    "array([[0.44442278, 0.28644582, 0.04357426, ..., 0.9425766 , 0.02024289,\n",
    "        0.88456545],\n",
    "       [0.77599317, 0.35188237, 0.54801261, ..., 0.91134102, 0.88599103,\n",
    "        0.88068835],\n",
    "       [0.68071886, 0.29352313, 0.95952505, ..., 0.19127958, 0.97723054,\n",
    "        0.36294011],\n",
    "       ...,\n",
    "       [0.03589378, 0.85429694, 0.33437761, ..., 0.39784873, 0.80368014,\n",
    "        0.76368042],\n",
    "       [0.01498725, 0.78155695, 0.80372969, ..., 0.82051826, 0.42314861,\n",
    "        0.18655465],\n",
    "       [0.69263802, 0.82090775, 0.27150426, ..., 0.86582747, 0.40896573,\n",
    "        0.33423976]])\n",
    "```\n",
    "\n",
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ –º–∞—Ç—Ä–∏—Ü–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —Ä–∞–∑–º–µ—Ä–æ–º —Å–ª–æ–≤–∞—Ä—è, —Ç–æ –µ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–≤–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥. –ü–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—É `num_tokens` –¥–æ–ª–∂–Ω–æ –±—Ä–∞—Ç—å –Ω–µ –±–æ–ª–µ–µ —É–∫–∞–∑–∞–Ω–æ –≤ —ç—Ç–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä—å –∏ –º–∞—Ç—Ä–∏—Ü—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5431219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –∏ —Å–∫–∞—á–∞–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "# !wget  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
    "# !gzip -d cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a34e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2index: Dict[str, int] = {}\n",
    "embeddings_matrix: np.array = []\n",
    "\n",
    "with open(\"small.vec\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for idx, line in enumerate(lines):\n",
    "        if idx == 0: continue\n",
    "        line = line.split(\" \")\n",
    "        word, embedd = line[0],  line[1:]\n",
    "        \n",
    "        token2index[word] = idx-1\n",
    "        embeddings_matrix.append(embedd)\n",
    "\n",
    "        if idx == 30: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43db8ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0326, -0.1499,  0.0232, ..., -0.0237, -0.0261, -0.1832],\n",
       "       [-0.0555, -0.0175,  0.0936, ...,  0.0201,  0.0535, -0.3563],\n",
       "       [-0.0312, -0.0627,  0.0326, ...,  0.0398, -0.2425, -0.2647],\n",
       "       ...,\n",
       "       [-0.0044, -0.1126, -0.026 , ...,  0.1368, -0.2307, -0.3249],\n",
       "       [-0.063 ,  0.0324, -0.0932, ...,  0.1149,  0.0648,  0.0566],\n",
       "       [ 0.1825, -0.0233, -0.0524, ..., -0.0023, -0.1985,  0.0598]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embeddings_matrix, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e15a9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path, num_tokens=100_000):\n",
    "\n",
    "    # –ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –∑–¥–µ—Å—å\n",
    "    # –≠—Ç–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫ —Ç–∏–ø—É\n",
    "    token2index: Dict[str, int] = {}\n",
    "    embeddings_matrix: np.array = []\n",
    "    pad_token = 'PAD'\n",
    "    unk_token = 'UNK'\n",
    "\n",
    "    token2index[pad_token] = 0\n",
    "    embeddings_matrix.append(np.zeros(300))\n",
    "\n",
    "    token2index[unk_token] = 1\n",
    "    embeddings_matrix.append(np.zeros(300))\n",
    "            \n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for idx, line in enumerate(lines):\n",
    "            if idx == 0: continue\n",
    "            line = line.split(\" \")\n",
    "            word, embedd = line[0],  line[1:]\n",
    "            \n",
    "            token2index[word] = idx-1\n",
    "            embeddings_matrix.append(embedd)\n",
    "   \n",
    "    embeddings_matrix = np.array(embeddings_matrix, dtype=float)\n",
    "    assert(len(token2index) == embeddings_matrix.shape[0])\n",
    "    \n",
    "    return token2index, embeddings_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fc5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2index, embeddings_matrix = load_embeddings(\"small.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d6819a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0,\n",
       " 'UNK': 1,\n",
       " ',': 0,\n",
       " '.': 1,\n",
       " '–∏': 2,\n",
       " '–≤': 3,\n",
       " '</s>': 4,\n",
       " ':': 5,\n",
       " ')': 6,\n",
       " '(': 7,\n",
       " '–Ω–∞': 8,\n",
       " '\"': 9,\n",
       " '—Å': 10,\n",
       " '–Ω–µ': 11,\n",
       " '¬ª': 12,\n",
       " '–¥–ª—è': 13,\n",
       " '-': 14,\n",
       " '¬´': 15,\n",
       " '/': 16,\n",
       " '–ø–æ': 17,\n",
       " '‚Äî': 18,\n",
       " '—á—Ç–æ': 19,\n",
       " '–í': 20,\n",
       " '!': 21,\n",
       " '–∏–∑': 22,\n",
       " '–æ—Ç': 23,\n",
       " '–∫': 24,\n",
       " '–∫–∞–∫': 25,\n",
       " '?': 26,\n",
       " '–∞': 27,\n",
       " '‚Äì': 28,\n",
       " '–∑–∞': 29,\n",
       " ';': 30,\n",
       " '–æ': 31,\n",
       " '–∏–ª–∏': 32,\n",
       " '—ç—Ç–æ': 33,\n",
       " 'ÔøΩ': 34,\n",
       " '1': 35,\n",
       " '...': 36,\n",
       " '_': 37,\n",
       " \"'\": 38,\n",
       " '–µ–≥–æ': 39,\n",
       " '—É': 40,\n",
       " '–¥–æ': 41,\n",
       " '|': 42,\n",
       " '2': 43,\n",
       " '–Ω–æ': 44,\n",
       " '–≤—Å–µ': 45,\n",
       " '–≥–æ–¥–∞': 46,\n",
       " '+': 47,\n",
       " '—è': 48,\n",
       " '—Ç–æ': 49,\n",
       " '%': 50,\n",
       " '–ø—Ä–∏': 51,\n",
       " '–æ–Ω': 52,\n",
       " '—Ç–∞–∫': 53,\n",
       " '–∂–µ': 54,\n",
       " '—Ç–æ–ª—å–∫–æ': 55,\n",
       " '3': 56,\n",
       " '–∏—Ö': 57,\n",
       " '–ê': 58,\n",
       " '–º–æ–∂–Ω–æ': 59,\n",
       " '#': 60,\n",
       " '–±—ã–ª': 61,\n",
       " '–ò': 62,\n",
       " '–≤—Ä–µ–º—è': 63,\n",
       " '—Ç–∞–∫–∂–µ': 64,\n",
       " '–≥–æ–¥—É': 65,\n",
       " '10': 66,\n",
       " '–±—ã–ª–æ': 67,\n",
       " '–±—É–¥–µ—Ç': 68,\n",
       " '–º–æ–∂–µ—Ç': 69,\n",
       " '–≤—ã': 70,\n",
       " '0': 71,\n",
       " '—É–∂–µ': 72,\n",
       " '[': 73,\n",
       " ']': 74,\n",
       " '4': 75,\n",
       " '>': 76,\n",
       " '—á—Ç–æ–±—ã': 77,\n",
       " '–µ—Å—Ç—å': 78,\n",
       " '–ù–∞': 79,\n",
       " '–µ—Å–ª–∏': 80,\n",
       " '5': 81,\n",
       " '‚Ä¶': 82,\n",
       " '–≥': 83,\n",
       " '–∫–æ—Ç–æ—Ä—ã–µ': 84,\n",
       " '–°': 85,\n",
       " '–±–µ–∑': 86,\n",
       " '—Å–æ': 87,\n",
       " '–æ—á–µ–Ω—å': 88,\n",
       " '–±—ã': 89,\n",
       " '–º—ã': 90,\n",
       " '—ç—Ç–æ–º': 91,\n",
       " '–±–æ–ª–µ–µ': 92,\n",
       " '–ø–æ–¥': 93,\n",
       " '–æ–Ω–∏': 94,\n",
       " '–±—ã—Ç—å': 95,\n",
       " '–†–æ—Å—Å–∏–∏': 96,\n",
       " '–≤–æ': 97,\n",
       " '–Ø': 98}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b2b68",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "–ú—ã —Å—Ä–∞–∑—É –ø–æ–ª—É—á–∏–º `torch.utils.data.Dataset`, –∫–æ—Ç–æ—Ä—ã–π —Å–º–æ–∂–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å –≤ `torch.utils.data.DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54fdaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Found cached dataset tweet_eval (/home/jovyan/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "Found cached dataset tweet_eval (/home/jovyan/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "Found cached dataset tweet_eval (/home/jovyan/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"tweet_eval\"\n",
    "dataset_name = \"sentiment\"\n",
    "\n",
    "train_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"train\")\n",
    "valid_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"validation\")\n",
    "test_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a0650",
   "metadata": {},
   "source": [
    "## `torch.utils.data.DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc742027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9012ae5",
   "metadata": {},
   "source": [
    "## –ü–æ—Å–º–æ—Ç—Ä–∏–º —á—Ç–æ –æ—Ç–¥–∞–µ—Ç –Ω–∞–º `Loader`\n",
    "–≠—Ç–æ –±–∞—Ç—á —Ñ–æ—Ä–º–∞—Ç–∞:\n",
    "```python\n",
    "batch = {\n",
    "    \"text\": [\n",
    "        \"text1\",\n",
    "        \"text2\",\n",
    "        ...,\n",
    "        \"textn\"\n",
    "    ],\n",
    "    \"label\": tensor([\n",
    "        1,\n",
    "        1,\n",
    "        ...,\n",
    "        0\n",
    "    ])\n",
    "}\n",
    "```\n",
    "–¢–æ –µ—Å—Ç—å —É –Ω–∞—Å –µ—Å—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –∫–ª—é—á–∞–º–∏ `text` –∏ `label`, –≥–¥–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è n –ø—Ä–∏–º–µ—Ä–æ–≤. –¢–æ –µ—Å—Ç—å –¥–ª—è 5-–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –≤ –±–∞—Ç—á–µ —Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è –≤ `batch[\"text\"][5]`, –∞ –∏–Ω–¥–µ–∫—Å –∫–ª–∞—Å—Å–∞ –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è –≤ `batch[\"label\"][5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bf6b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['ICC announces teams for WCL Division 3: Dubai: The International Cricket Council (ICC) Thursday announced the ...',\n",
       "  \"Wasn't there an International Women's day on the 8th of March too?\"],\n",
       " 'label': tensor([1, 1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    break\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b9f0e6",
   "metadata": {},
   "source": [
    "## Collate\n",
    "–°–µ–π—á–∞—Å –ø–µ—Ä–µ–¥ –Ω–∞–º–∏ —Å—Ç–æ–∏—Ç –ø—Ä–æ–±–ª–µ–º–∞: –º—ã –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç—ã –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫, –∞ –Ω–∞–º –Ω—É–∂–Ω—ã —Ç–µ–Ω–∑–æ—Ä—ã (–º–∞—Ç—Ä–∏—Ü—ã) —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Ç–æ–∫–µ–Ω–æ–≤, –∫ —Ç–æ–º—É –∂–µ –Ω–∞–º –Ω—É–∂–Ω–æ –∑–∞–ø–∞–¥–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤, —á—Ç–æ–±—ã –≤—Å–µ —Å–ª–æ–∂–∏—Ç—å –≤ —Ç–æ—Ä—á–æ–≤—É—é –º–∞—Ç—Ä–∏—Ü—É. –ú—ã –º–æ–∂–µ–º —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –¥–≤—É–º—è —Å–ø–æ—Å–æ–±–∞–º–∏:\n",
    "- –î–æ—Å—Ç–∞—Ç—å –∏–∑ `train/valid/test_dataset` –¥–∞–Ω–Ω—ã–µ –∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π `Dataset`, –≥–¥–µ –≤–Ω—É—Ç—Ä–∏ –±—É–¥–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, —Ç–æ–∫–µ–Ω—ã –±—É–¥—É—Ç –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å—Å—è –≤ –∏–Ω–¥–µ–∫—Å—ã –∏ –∑–∞—Ç–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±—É–¥–µ—Ç –ø–∞–¥–∏—Ç—å—Å—è –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏–Ω—ã\n",
    "- –°–¥–µ–ª–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –±—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏ –Ω–∞—à–∏ –±–∞—Ç—á–∏. –û–Ω–∞ –≤—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤ `DataLoader(collate_fn=<–í–ê–®–ê_–§–£–ù–ö–¶–ò–Ø>)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b0f2e",
   "metadata": {},
   "source": [
    "## –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Å–≤–æ–π `Dataset`\n",
    "–¢–æ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ—Å—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26771f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45615, 45615)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[\"text\"]), len(train_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25200be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"',\n",
       " '\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"text\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c952b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"label\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68184652",
   "metadata": {},
   "source": [
    "## –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å `collate_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706dab4d",
   "metadata": {},
   "source": [
    "### –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º —á—Ç–æ –≤–æ–æ–±—â–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞\n",
    "–î–ª—è —ç—Ç–æ–≥–æ —Å–¥–µ–ª–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é `empty_collate`, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –±–∞—Ç—á –∏ –æ—Ç–¥–∞–µ—Ç –µ–≥–æ, –Ω–∏—á–µ–≥–æ —Å –Ω–∏–º –Ω–µ –¥–µ–ª–∞—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b7ce86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_collate(batch):\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f0fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=empty_collate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=empty_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=empty_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "942cf78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Face like miss America... Body like a stripper... Fuck me like a pornstar... N handle business like the 1st lady... Yea i need that...$$$',\n",
       "  'label': 2},\n",
       " {'text': '@user @user By the IRA? On bloody sunday 13 innocent demonstrators where gunned down in cold blood.',\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    break\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca5081",
   "metadata": {},
   "source": [
    "## –§–æ—Ä–º–∞—Ç –±–∞—Ç—á–∞\n",
    "```python\n",
    "batch = [\n",
    "    {\n",
    "        \"text\": \"text1\",\n",
    "        \"label\": 0\n",
    "    }, \n",
    "    {\n",
    "        \"text\": \"text2\",\n",
    "        \"label\": 1\n",
    "    },\n",
    "    ...,\n",
    "    {\n",
    "        \"text\": \"textn\",\n",
    "        \"label\": 1\n",
    "    }\n",
    "]\n",
    "```\n",
    "–¢–æ –µ—Å—Ç—å —Ç–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫, –≥–¥–µ –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç ‚Äî —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ `text` –∏ `label`.  \n",
    "\n",
    "–í—ã –º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∏–ª–∏ –∫–ª–∞—Å—Å —Å –º–µ—Ç–æ–¥–æ–º `collate`. –≠—Ç–æ—Ç —Å–ø–æ—Å–æ–± —Ä–µ—à–µ–Ω–∏—è –¥–æ–º–∞—à–∫–∏ –ø—Ä–µ–¥–æ–¥—á—Ç–∏—Ç–µ–ª—å–Ω–µ–π, —Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `collate` –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞.\n",
    "\n",
    "–ß—Ç–æ —è –ø—Ä–µ–¥–ª–∞–≥–∞—é:\n",
    "- –°–¥–µ–ª–∞–π—Ç–µ –∫–ª–∞—Å—Å `Tokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b9ddcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, base_tokenizer, token2index, pad_token, unk_token, max_length):\n",
    "        \n",
    "        self._base_tokenizer = ToktokTokenizer()  # –Ω–∞–ø—Ä–∏–º–µ—Ä ToktokTokenizer()\n",
    "        \n",
    "        self.token2index = token2index  # —Å–ª–æ–≤–∞—Ä—å –∏–∑ load_embeddings()\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.token2index[self.pad_token]\n",
    "        \n",
    "        self.unk_token = unk_token\n",
    "        self.unk_index = self.token2index[self.unk_token]\n",
    "        \n",
    "        self.max_length = max_length\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        –í —ç—Ç–æ–º –º–µ—Ç–æ–¥–µ –Ω—É–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Å—Ç—Ä–æ–∫—É —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–∫–µ–Ω—ã\n",
    "        \"\"\"\n",
    "        return self._base_tokenizer.tokenize(text)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        \"\"\"\n",
    "        –í —ç—Ç–æ–º –º–µ—Ç–æ–¥–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–ø–∏—Å–æ–∫ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —ç—Ç–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤\n",
    "        \"\"\"\n",
    "        token_indices = list()\n",
    "        for i, v in enumerate(tokenized_text):\n",
    "            if v in self.token2index:\n",
    "                token_indices.append(self.token2index[v])\n",
    "            else:\n",
    "                token_indices.append(self.unk_index)\n",
    "        return token_indices\n",
    "        \n",
    "    def padding(self, tokens_indices):\n",
    "        \"\"\"\n",
    "        –í —ç—Ç–æ–º –º–µ—Ç–æ–¥–µ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–ª–∏–Ω—É tokens_indices —Ä–∞–≤–Ω–æ–π self.max_length\n",
    "        –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–±—Ä–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è unk'–∏\n",
    "        \"\"\"\n",
    "        if len(tokens_indices) > self.max_length:\n",
    "            tokens_indices = tokens_indices[:self.max_length]\n",
    "       \n",
    "        if len(tokens_indices) < self.max_length:\n",
    "            tokens_indices = tokens_indices + np.zeros(self.max_length - len(tokens_indices), dtype=int).tolist()\n",
    "\n",
    "        return tokens_indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # tokens_indices = tokens_indices[:self.max_length]\n",
    "        # return tokens_indices\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        \"\"\"\n",
    "        –í —ç—Ç–æ–º –º–µ—Ç–æ–¥–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫—É —Å —Ç–µ–∫—Å—Ç–æ–º –≤ –≤–µ–∫—Ç–æ—Ä —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Å–ª–æ–≤ –Ω—É–∂–Ω–æ —Ä–∞–∑–º–µ—Ä–∞ (self.max_length)\n",
    "        \"\"\"\n",
    "        # if list(token2index.keys()) in text.split(\" \"):\n",
    "        #     text_indicies = \n",
    "        # text = np.array(token2index)\n",
    "        # return \n",
    "        tokenized_text = self.tokenize(text)\n",
    "        tokens_indices = self.indexing(tokenized_text)\n",
    "        tokens_indices = self.padding(tokens_indices)\n",
    "        return tokens_indices\n",
    "       \n",
    "\n",
    "        \n",
    "    def collate(self, batch):\n",
    "        \n",
    "        tokenized_texts = list()\n",
    "        labels = list()\n",
    "        \n",
    "        for sample in batch:\n",
    "            tokenized_texts.append(self.__call__(sample[\"text\"]))\n",
    "            labels.append(sample[\"label\"])\n",
    "\n",
    "\n",
    "        tokenized_texts = torch.tensor(tokenized_texts) # –ø–µ—Ä–µ–≤–æ–¥ –≤ torch.Tensor\n",
    "        labels = torch.tensor(labels) # –ø–µ—Ä–µ–≤–æ–¥ –≤ torch.Tensor\n",
    "        \n",
    "        return tokenized_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ba94d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.5500e-02, -1.7500e-02,  9.3600e-02,  2.4500e-02, -7.0800e-02,\n",
       "        4.4900e-02,  2.8900e-02,  9.9900e-02, -6.1000e-03, -1.2660e-01,\n",
       "        6.4600e-02, -1.6190e-01,  1.3480e-01, -3.5000e-02,  2.9000e-03,\n",
       "       -8.3100e-02, -1.9700e-02,  9.5500e-02,  2.6500e-02, -7.1400e-02,\n",
       "        4.5000e-02, -1.9740e-01,  1.8700e-02, -2.5000e-03, -2.8500e-02,\n",
       "       -5.5700e-02, -6.0000e-04,  9.2600e-02,  6.5000e-03,  2.6000e-03,\n",
       "       -1.5610e-01, -5.2200e-02, -5.2000e-03,  1.4440e-01, -1.5500e-02,\n",
       "        7.7900e-02, -9.4400e-02, -1.0973e+00,  7.1200e-02,  2.4000e-03,\n",
       "        1.9500e-02, -1.3380e-01,  3.1000e-03,  2.2200e-02, -1.2160e-01,\n",
       "       -2.4000e-03, -7.0900e-02, -2.4600e-02, -9.2600e-02, -1.4630e-01,\n",
       "       -2.0200e-02, -5.1600e-02, -4.9600e-02,  1.3520e-01,  7.9600e-02,\n",
       "       -7.4700e-02,  1.7600e-02,  1.1940e-01, -1.6950e-01,  4.8000e-02,\n",
       "       -5.9600e-01, -8.5400e-02,  1.0160e-01, -1.3600e-02, -2.9600e-02,\n",
       "       -2.1300e-02,  4.4000e-02,  8.9500e-02, -4.9000e-03, -5.7700e-02,\n",
       "        7.8000e-03, -4.4500e-02,  1.1370e-01,  2.5100e-02,  4.0000e-04,\n",
       "        7.4700e-02,  2.5000e-03, -3.1200e-02,  1.5090e-01,  5.6300e-02,\n",
       "        2.1900e-02,  2.4000e-02,  3.0300e-01,  6.3100e-02, -7.2000e-02,\n",
       "       -1.1120e-01,  2.3720e-01, -3.8100e-02, -3.3300e-02, -5.2400e-02,\n",
       "       -1.6440e-01,  5.6800e-02, -4.3300e-02, -2.0030e-01, -1.9000e-02,\n",
       "        3.7600e-02, -6.5200e-02,  2.0000e-02,  3.9840e-01, -5.1600e-02,\n",
       "       -4.6000e-03, -3.9120e-01, -6.2000e-02,  2.7300e-02,  3.2600e-02,\n",
       "        8.7000e-03, -3.6960e-01,  2.3600e-02, -8.6500e-02, -7.0000e-04,\n",
       "        4.8000e-02,  3.7200e-02,  1.3280e-01, -1.2600e-02,  9.6000e-03,\n",
       "       -1.0280e-01, -5.5000e-03,  2.0110e-01, -7.7300e-02, -4.7700e-02,\n",
       "        4.5100e-02,  5.9500e-02,  1.4500e-01, -1.0000e-03,  4.8500e-02,\n",
       "        8.2000e-03, -3.9500e-02, -1.6510e-01,  1.5200e-02, -7.1000e-02,\n",
       "        7.1000e-03,  8.1600e-02,  6.4100e-02, -4.4100e-02, -3.5900e-02,\n",
       "       -7.5000e-03, -2.2100e-01, -3.8700e-02, -2.3400e-01, -8.7000e-03,\n",
       "       -1.6300e-02, -9.9700e-02,  9.6700e-02,  1.9470e-01, -2.1360e-01,\n",
       "       -9.1000e-03,  2.2910e-01,  3.2980e-01,  2.9800e-02, -7.9300e-02,\n",
       "        4.2900e-02, -3.2000e-02,  2.7350e-01,  5.3700e-02,  6.0200e-02,\n",
       "        3.5000e-02, -8.8000e-03, -3.9200e-02, -1.6050e-01, -1.2840e-01,\n",
       "       -1.5200e-02,  5.9700e-02,  8.1200e-02,  7.6000e-03,  7.5900e-02,\n",
       "       -1.1670e-01,  5.6900e-02,  1.8600e-02, -6.9000e-03,  8.6400e-02,\n",
       "       -3.4500e-02,  1.4900e-02, -3.9100e-02, -1.3860e-01, -4.8520e-01,\n",
       "       -6.2400e-02, -1.2670e-01,  4.8500e-02,  8.3400e-02,  1.9500e-02,\n",
       "       -1.6900e-02, -1.3020e-01, -1.8500e-02, -2.1000e-03, -9.0900e-02,\n",
       "       -6.2600e-02,  5.4200e-02,  7.1900e-02, -2.3800e-02, -7.0500e-02,\n",
       "        1.2500e-02,  5.3500e-02,  1.1000e-02,  1.1410e-01,  4.9300e-02,\n",
       "        1.1600e-02, -1.0630e-01,  5.4600e-02, -8.3000e-03, -8.3700e-02,\n",
       "        4.8600e-02, -5.4000e-02,  4.4500e-02, -5.1100e-02, -7.3400e-02,\n",
       "        2.2200e-02, -1.6200e-02,  8.8000e-03, -1.0200e-02,  2.6400e-02,\n",
       "        1.6630e-01, -1.1200e-01, -1.0000e-04, -1.4300e-01, -3.4910e-01,\n",
       "        4.7500e-02, -6.8000e-02, -5.3800e-02,  4.6600e-02, -2.7400e-02,\n",
       "        1.1740e-01,  1.0370e-01,  2.8400e-02,  4.4000e-03, -6.3000e-03,\n",
       "       -1.7000e-02,  4.1700e-02,  1.2000e-02,  5.4000e-03, -1.2340e-01,\n",
       "       -5.1800e-02,  9.9500e-02, -1.5980e-01,  1.9980e-01,  2.5020e-01,\n",
       "       -7.1700e-02,  2.6500e-02, -4.0000e-03,  3.7200e-02, -2.0000e-02,\n",
       "        1.1530e-01,  1.6600e-01, -1.4800e-02, -3.8100e-02,  7.6200e-02,\n",
       "       -7.8100e-02, -8.8400e-02, -7.6600e-02,  1.0510e-01, -6.5200e-02,\n",
       "       -7.2680e-01,  4.8870e-01, -1.2010e-01, -2.5400e-02,  5.0000e-04,\n",
       "        6.3000e-03,  2.0400e-01,  6.8400e-02,  4.0000e-04,  1.3390e-01,\n",
       "       -1.0000e-04,  1.1100e-01,  3.2390e-01,  4.1500e-02, -5.0300e-02,\n",
       "        4.4300e-02,  1.6000e-03,  6.5000e-03, -3.5190e-01,  1.6900e-02,\n",
       "        4.9000e-03, -2.0000e-03,  5.6910e-01,  8.5100e-02,  9.0400e-02,\n",
       "       -7.6500e-02, -5.8800e-02, -5.8100e-02, -1.4700e-02,  2.2300e-02,\n",
       "        1.6490e-01,  3.7800e-02,  2.1000e-03,  1.8600e-02,  9.0300e-02,\n",
       "        6.5000e-02,  1.6000e-03,  1.3530e-01,  1.6690e-01, -4.4600e-02,\n",
       "       -3.9000e-03,  3.0000e-03, -1.9250e-01, -7.8000e-03, -4.2010e-01,\n",
       "        3.7200e-02, -4.8300e-02,  2.0100e-02,  5.3500e-02, -3.5630e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d69d067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0,\n",
       " 'UNK': 1,\n",
       " ',': 0,\n",
       " '.': 1,\n",
       " '–∏': 2,\n",
       " '–≤': 3,\n",
       " '</s>': 4,\n",
       " ':': 5,\n",
       " ')': 6,\n",
       " '(': 7,\n",
       " '–Ω–∞': 8,\n",
       " '\"': 9,\n",
       " '—Å': 10,\n",
       " '–Ω–µ': 11,\n",
       " '¬ª': 12,\n",
       " '–¥–ª—è': 13,\n",
       " '-': 14,\n",
       " '¬´': 15,\n",
       " '/': 16,\n",
       " '–ø–æ': 17,\n",
       " '‚Äî': 18,\n",
       " '—á—Ç–æ': 19,\n",
       " '–í': 20,\n",
       " '!': 21,\n",
       " '–∏–∑': 22,\n",
       " '–æ—Ç': 23,\n",
       " '–∫': 24,\n",
       " '–∫–∞–∫': 25,\n",
       " '?': 26,\n",
       " '–∞': 27,\n",
       " '‚Äì': 28,\n",
       " '–∑–∞': 29,\n",
       " ';': 30,\n",
       " '–æ': 31,\n",
       " '–∏–ª–∏': 32,\n",
       " '—ç—Ç–æ': 33,\n",
       " 'ÔøΩ': 34,\n",
       " '1': 35,\n",
       " '...': 36,\n",
       " '_': 37,\n",
       " \"'\": 38,\n",
       " '–µ–≥–æ': 39,\n",
       " '—É': 40,\n",
       " '–¥–æ': 41,\n",
       " '|': 42,\n",
       " '2': 43,\n",
       " '–Ω–æ': 44,\n",
       " '–≤—Å–µ': 45,\n",
       " '–≥–æ–¥–∞': 46,\n",
       " '+': 47,\n",
       " '—è': 48,\n",
       " '—Ç–æ': 49,\n",
       " '%': 50,\n",
       " '–ø—Ä–∏': 51,\n",
       " '–æ–Ω': 52,\n",
       " '—Ç–∞–∫': 53,\n",
       " '–∂–µ': 54,\n",
       " '—Ç–æ–ª—å–∫–æ': 55,\n",
       " '3': 56,\n",
       " '–∏—Ö': 57,\n",
       " '–ê': 58,\n",
       " '–º–æ–∂–Ω–æ': 59,\n",
       " '#': 60,\n",
       " '–±—ã–ª': 61,\n",
       " '–ò': 62,\n",
       " '–≤—Ä–µ–º—è': 63,\n",
       " '—Ç–∞–∫–∂–µ': 64,\n",
       " '–≥–æ–¥—É': 65,\n",
       " '10': 66,\n",
       " '–±—ã–ª–æ': 67,\n",
       " '–±—É–¥–µ—Ç': 68,\n",
       " '–º–æ–∂–µ—Ç': 69,\n",
       " '–≤—ã': 70,\n",
       " '0': 71,\n",
       " '—É–∂–µ': 72,\n",
       " '[': 73,\n",
       " ']': 74,\n",
       " '4': 75,\n",
       " '>': 76,\n",
       " '—á—Ç–æ–±—ã': 77,\n",
       " '–µ—Å—Ç—å': 78,\n",
       " '–ù–∞': 79,\n",
       " '–µ—Å–ª–∏': 80,\n",
       " '5': 81,\n",
       " '‚Ä¶': 82,\n",
       " '–≥': 83,\n",
       " '–∫–æ—Ç–æ—Ä—ã–µ': 84,\n",
       " '–°': 85,\n",
       " '–±–µ–∑': 86,\n",
       " '—Å–æ': 87,\n",
       " '–æ—á–µ–Ω—å': 88,\n",
       " '–±—ã': 89,\n",
       " '–º—ã': 90,\n",
       " '—ç—Ç–æ–º': 91,\n",
       " '–±–æ–ª–µ–µ': 92,\n",
       " '–ø–æ–¥': 93,\n",
       " '–æ–Ω–∏': 94,\n",
       " '–±—ã—Ç—å': 95,\n",
       " '–†–æ—Å—Å–∏–∏': 96,\n",
       " '–≤–æ': 97,\n",
       " '–Ø': 98}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e17fb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Face like miss America... Body like a stripper... Fuck me like a pornstar... N handle business like the 1st lady... Yea i need that...$$$',\n",
       "  'label': 2},\n",
       " {'text': '@user @user By the IRA? On bloody sunday 13 innocent demonstrators where gunned down in cold blood.',\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede957cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Face like miss America... Body like a stripper... Fuck me like a pornstar... N handle business like the 1st lady... Yea i need that...$$$'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab7e6d",
   "metadata": {},
   "source": [
    "## –ü–µ—Ä–µ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞\n",
    "–°–æ–≤–µ—Ç—É—é, —á—Ç–æ–±—ã –≤ –∏—Ç–æ–≥–µ `Loader` –æ—Ç–¥–∞–≤–∞–ª –∫–æ—Ä—Ç–µ–∂ —Å –¥–≤—É–º—è —Ç–µ–Ω–∑–æ—Ä–∞–º–∏:\n",
    "- `torch.Tensor` —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Ç–æ–∫–µ–Ω–æ–≤, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å `(batch_size, sequence_length)`\n",
    "- `torch.Tensor` —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Ç–∞—Ä–≥–µ—Ç–æ–≤, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å `(batch_size)`\n",
    "\n",
    "–¢–æ –µ—Å—Ç—å, —á—Ç–æ–±—ã –±—ã–ª–æ —Ç–∞–∫:\n",
    "```python\n",
    "for x, y in train_loader:\n",
    "    ...\n",
    "\n",
    ">> x\n",
    ">> tensor([[   37,  3889,   470,  ...,     0,     0,     0],\n",
    "           [ 1509,   581,   144,  ...,     0,     0,     0],\n",
    "           [ 1804,   893,  2457,  ...,     0,     0,     0],\n",
    "           ...,\n",
    "           [  170, 39526,  2102,  ...,     0,     0,     0],\n",
    "           [ 1217,   172, 28440,  ...,     0,     0,     0],\n",
    "           [   37,    56,   603,  ...,     0,     0,     0]])\n",
    "\n",
    ">> y\n",
    ">> tensor([1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1,\n",
    "           0, 2, 1, 1, 0, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
    "           1, 0, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 0, 1, 0, 2, 1, 2, 2, 1, 0, 0, 2, 2,\n",
    "           2, 1, 2, 0, 2, 2, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 0, 2, 2,\n",
    "           2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1,\n",
    "           2, 1, 1, 2, 2, 1, 1, 2])\n",
    "\n",
    ">> x.shape\n",
    ">> torch.Size([128, 64])\n",
    "\n",
    ">> y.shape\n",
    ">> torch.Size([128])\n",
    "```\n",
    "–ü—Ä–∏ —É—Å–ª–æ–≤–∏–∏, —á—Ç–æ –±–∞—Ç—á —Å–∞–π–∑ —Ä–∞–≤–µ–Ω 128, –∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–≤–Ω–∞ 64.\n",
    "\n",
    "## –ü–æ–º–Ω–∏—Ç–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cf71c",
   "metadata": {},
   "source": [
    "## <–ú–µ—Å—Ç–æ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d90d7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(ToktokTokenizer, token2index, 'PAD', 'UNK', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dc61cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  1,  1,  1, 36,  1,  1,  1,  1, 36,  1,  1,  1,  1,  1, 36,  1,  1,\n",
       "           1,  1,  1,  1,  1, 36,  1,  1,  1,  1, 36,  1,  1,  1,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1,  1,  1,  1,  1, 26,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " tensor([2, 0]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40268f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=tokenizer.collate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, collate_fn=tokenizer.collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, collate_fn=tokenizer.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d293b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87752ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(isinstance(x, torch.Tensor))\n",
    "assert(len(x.size()) == 2)\n",
    "\n",
    "assert(isinstance(y, torch.Tensor))\n",
    "assert(len(y.size()) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc96104",
   "metadata": {},
   "source": [
    "# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è DAN\n",
    "\n",
    "–ù–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –ø–æ–¥–∞–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤\n",
    "\n",
    "–®–∞–≥–∏:\n",
    "- –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤ –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "- –£—Å—Ä–µ–¥–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "- –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ `Multilayer Perceptron`\n",
    "    - –ù—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–∞–º–æ–º—É\n",
    "\n",
    "### –ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤ –¥–æ–º–∞—à–∫–µ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–µ—Ç–∏:\n",
    "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å skip-connection (residual connection) –≤ –ª–∏–Ω–µ–π–Ω–æ–º —Å–ª–æ–µ\n",
    "- –ù–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π —Å–ª–æ–π, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥—É—Ç (–ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–µ–≤ –Ω–∏–∂–µ –Ω–∞–ø—É—Ç–∞–Ω, —Ç–∞–∫ —á—Ç–æ —Å–∞–º–∏ –ø–æ–¥—É–º–∞–π—Ç–µ –≤ –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ —Å—Ç–æ–∏—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–∏—Ç—å —ç—Ç–∏ —Å–ª–æ–∏) :\n",
    "  - `Dropout`\n",
    "  - `BatchNorm` / `LayerNorm`\n",
    "  - `Residual`, –µ—Å–ª–∏ –≤—ã –Ω–µ –º–µ–Ω—è–µ—Ç–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤\n",
    "  - –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "  - –õ–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π\n",
    "\n",
    "### –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è:\n",
    "- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `transformers`\n",
    "- –°–¥–µ–ª–∞—Ç—å —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å —É—á–µ—Ç–æ–º –ø–∞–¥–æ–≤\n",
    "  - –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–¥—ã, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –µ–¥–∏–Ω—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –≤ –±–∞—Ç—á–µ\n",
    "    - –¢–æ –µ—Å—Ç—å —É –Ω–∞—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≤ –±–∞—Ç—á–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, 16 —Ç–æ–∫–µ–Ω–æ–≤, –ø–æ—ç—Ç–æ–º—É –∫–æ –≤—Å–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º, —É –∫–æ—Ç–æ—Ä—ã—Ö –¥–ª–∏–Ω–∞ –Ω–∏–∂–µ –º—ã –¥–æ–±–∞–≤–ª—è–µ–º `16 - len(sequence)` –ø–∞–¥–æ–≤\n",
    "  - –¢–æ –µ—Å—Ç—å –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Ç–∞–∫, —á—Ç–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥–ª–∏–Ω—ã –≤ –±–∞—Ç—á–µ, –ø–æ—Ç–æ–º—É —á—Ç–æ\n",
    "    - –°—Ä–µ–¥–Ω–µ–µ –≤–µ–∫—Ç–æ—Ä–∞ `[1, 2, 3]` –±—É–¥–µ—Ç `2`. –°—Ä–µ–¥–Ω–µ–µ –≤–µ–∫—Ç–æ—Ä–∞ `[1, 2, 3, 0, 0]` –±—É–¥–µ—Ç `1.2`\n",
    "    - –ü–æ–ª—É—á–∞–µ—Ç—Å—è, —á—Ç–æ —É—Å—Ä–µ–¥–Ω—è—è —Å –ø–∞–¥–∞–º–∏ –º—ã –ø–æ–ª—É—á–∞–µ–º \"–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π\" –≤–µ–∫—Ç–æ—Ä\n",
    "  - –¢–æ –µ—Å—Ç—å –Ω–∞—à–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—É–¥—É—Ç –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç —Ç–æ–≥–æ —Å–∫–æ–ª—å–∫–æ –ø–∞–¥–æ–≤ —É –Ω–∞—Å –µ—Å—Ç—å –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏\n",
    "  - –ö–æ–≥–¥–∞ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—à—É —Å–µ—Ç–∫—É –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –º—ã –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –≤ –Ω–µ–µ –ø–æ –æ–¥–Ω–æ–º—É –ø—Ä–∏–º–µ—Ä—É, –≥–¥–µ –ø–∞–¥–æ–≤ –Ω–µ –±—É–¥–µ—Ç\n",
    "    - –¢–æ –µ—Å—Ç—å –ø–æ–ª—É—á–∞–µ—Ç—Å—è –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—à—É –º–æ–¥–µ–ª—å –Ω–µ –≤ —Ç–æ–π –∂–µ —Å—Ä–µ–¥–µ, –∫–∞–∫ –∏ –æ–±—É—á–∞–ª–∏\n",
    "      - –ü–æ—Ç–æ–º—É —á—Ç–æ –Ω–∞—à–∏ –≤—Ö–æ–¥—ã –º–µ–Ω—è—é—Ç—Å—è, –º—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–¥—ã, —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –¥—Ä—É–≥–æ–π\n",
    "    - –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è `distribution shift`, —Ç–æ –µ—Å—Ç—å –∫–æ–≥–¥–∞ –º—ã —É—á–∏–º—Å—è –Ω–∞ –æ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞ –¥—Ä—É–≥–∏—Ö\n",
    "      - –≠—Ç–æ –Ω–µ –≤—Å–µ–≥–¥–∞ –ø–ª–æ—Ö–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –∏–Ω–æ–≥–¥–∞ —Ç–æ–ª—å–∫–æ —Ç–∞–∫ –º—ã –∏ –º–æ–∂–µ–º —É—á–∏—Ç—å—Å—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–≥–¥–∞ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –Ω—É–∂–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞\n",
    "      - –≠—Ç–æ –ø–ª–æ—Ö–æ —Ç–æ–≥–¥–∞, –∫–æ–≥–¥–∞ –º—ã –≤–Ω–æ—Å–∏–º —ç—Ç–æ \"—Å–ª—É—á–∞–π–Ω–æ\", –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∫ —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ–º, —Ç–æ –µ—Å—Ç—å —ç—Ç–æ —Å–≤–æ–µ–±—Ä–∞–∑–Ω—ã–π –±–∞–≥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123324f0",
   "metadata": {},
   "source": [
    "## –î–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "- –í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫—É(–∫–∏) –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ—á–µ–º—É –æ–Ω–∞(–æ–Ω–∏)\n",
    "    - –û–±—ã—á–Ω–æ –µ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–∏–Ω–∏–º–∞–µ–º —Ä–µ—à–µ–Ω–∏—è –∫–∞–∫–∏–µ –≤–µ—Å–∞ –±—Ä–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–º –ø–æ–º–æ–≥—É—Ç –¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, –æ —Ç–æ–º –≤—Å–µ –ª–∏ —Ö–æ—Ä–æ—à–æ —Å –Ω–∞—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏, —Ö–æ—Ä–æ—à–æ –ª–∏ –º–æ–¥–µ–ª—å —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤ –∏ —Ç–¥\n",
    "- –≠—Ç—É –¥–æ–º–∞—à–∫—É –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∏ –Ω–∞ `CPU`, –Ω–æ –Ω–∞ `GPU` –±—É–¥–µ—Ç —Å–∏–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ\n",
    "    - –í–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –¥–æ–º–∞—à–∫–∞—Ö –º—ã –±—É–¥–µ–º —É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ `GPU`\n",
    "    - –†–∞–Ω–æ –∏–ª–∏ –ø–æ–∑–¥–Ω–æ –≤–∞–º –ø—Ä–∏–¥–µ—Ç—Å—è –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —ç—Ç–æ—Ç [—Ç—É—Ç–æ—Ä–∏–∞–ª](https://www.youtube.com/watch?v=pgk1zGv5lU4)\n",
    "    - –í—ã –º–æ–∂–µ—Ç–µ –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ `colab`, —ç—Ç–æ –±–µ—Å–ø–ª–∞—Ç–Ω–æ\n",
    "\n",
    "## –î–æ —ç–ø–æ—Ö–∏\n",
    "- –°–¥–µ–ª–∞–π—Ç–µ —Å–ø–∏—Å–∫–∏/—Å–ª–æ–≤–∞—Ä–∏/–¥—Ä—É–≥–æ–µ, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫(–∏) –ø–æ –≤—Å–µ–π —ç–ø–æ—Ö–µ –¥–ª—è —Ç—Ä–µ–π–Ω–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "\n",
    "## –í–æ –≤—Ä–µ–º—è —ç–ø–æ—Ö–∏\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ [`tqdm`](https://github.com/tqdm/tqdm) –∫–∞–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞—Ç—å –∫–∞–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç –≤–∞—à–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "- –õ–æ–≥–∏—Ä—É–π—Ç–µ –ª–æ—Å—Å\n",
    "- –õ–æ–≥–∏—Ä—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫—É(–∫–∏) –ø–æ –±–∞—Ç—á—É\n",
    "- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Ç–æ, —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã –ø–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫(–∏) –Ω–∞ –≤—Å—é —ç–ø–æ—Ö—É –¥–ª—è —Ç—Ä–µ–π–Ω–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "\n",
    "## –ü–æ—Å–ª–µ —ç–ø–æ—Ö–∏\n",
    "- –ü–æ—Å—á–∏—Ç–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫(–∏) –Ω–∞ –≤—Å—é —ç–ø–æ—Ö—É –¥–ª—è —Ç—Ä–µ–π–Ω–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "\n",
    "## –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "- –ü—Ä–æ–≤–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –∏ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "- –ü–æ—Å—Ç—Ä–æ–π—Ç–µ [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "- –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏:\n",
    "    - [Confusion Matrix](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix)\n",
    "    - [–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ] –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –º–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ (—Ç–æ –µ—Å—Ç—å –¥–ª—è –∫–∞–∫–æ–≥–æ-—Ç–æ –ø—Ä–∏–º–µ—Ä–∞ –º—ã –≤—ã–±–∏—Ä–∞–µ–º —Ç–∞–∫–æ–π –∫–ª–∞—Å—Å –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —ç—Ç–æ–≥–æ –≤—ã–±–æ—Ä–∞ —Ç–∞–∫–∞—è-—Ç–æ) –Ω–∞ —Ç—Ä–µ–π–Ω–µ/—Ç–µ—Å—Ç–µ/–≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "        - –ï—Å–ª–∏ –∫–ª–∞—Å—Å –±—ã–ª –≤—ã–±—Ä–∞–Ω –≤–µ—Ä–Ω–æ –∏ –µ—Å–ª–∏ –±—ã–ª–∞ –æ—à–∏–±–∫–∞\n",
    "- –ü–æ–¥—É–º–∞–π—Ç–µ —á—Ç–æ –µ—â–µ –≤–∞–º –±—É–¥–µ—Ç –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —Ç–∞–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã: \n",
    "    - –ß—Ç–æ –≤ –º–æ–¥–µ–ª–µ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å?\n",
    "    - –í—Å–µ –ª–∏ —Ö–æ—Ä–æ—à–æ —Å –º–æ–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏?\n",
    "    - –í—Å–µ –ª–∏ —Ö–æ—Ä–æ—à–æ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π?\n",
    "    - –ù–µ –ø–µ—Ä–µ–æ–±—É—á–∏–ª—Å—è –ª–∏ —è?\n",
    "    - –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —è –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –¥–∞–Ω–Ω—ã–µ?\n",
    "    - –ù—É–∂–Ω–æ –ª–∏ –º–Ω–µ —É–ª—É—á—à–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö?\n",
    "    - –ù—É–∂–Ω–æ –ª–∏ –ø–æ–º–µ–Ω—è—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –∏–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏?\n",
    "    - –ù–µ—Ç –ª–∏ —É –º–µ–Ω—è –±–∞–≥–æ–≤ –≤ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏?\n",
    "    - –ö–∞–∫–∏–µ —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ —É –º–æ–µ–π –º–æ–¥–µ–ª–∏?\n",
    "    - –ö–∞–∫ —è –º–æ–≥—É –∏—Ö –∏—Å–ø—Ä–∞–≤–∏—Ç—å?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f451c",
   "metadata": {},
   "source": [
    "# –Ø –≤—ã–±—Ä–∞–ª –º–µ—Ç—Ä–∏–∫—É <–ú–ï–¢–†–ò–ö–ê>\n",
    "\n",
    "> –≠—Ç–æ –º–æ—è –º–µ—Ç—Ä–∏–∫–∞. –¢–∞–∫–∏—Ö –º–µ—Ç—Ä–∏–∫ –º–Ω–æ–≥–æ, –Ω–æ —ç—Ç–∞ –º–æ—è. –ú–æ—è –º–µ—Ç—Ä–∏–∫–∞ ‚Äî –º–æ–π –ª—É—á—à–∏–π –¥—Ä—É–≥. –≠—Ç–æ ‚Äî –º–æ—è –∂–∏–∑–Ω—å. –Ø –¥–æ–ª–∂–µ–Ω –Ω–∞—É—á–∏—Ç—å—Å—è –≤–ª–∞–¥–µ—Ç—å –º–µ—Ç—Ä–∏–∫–æ–π —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤–ª–∞–¥–µ—é —Å–≤–æ–µ–π –∂–∏–∑–Ω—å—é. –ë–µ–∑ –º–µ–Ω—è –º–æ—è –º–µ—Ç—Ä–∏–∫–∞ –±–µ—Å–ø–æ–ª–µ–∑–Ω–∞. –ë–µ–∑ –º–æ–µ–π –º–µ—Ç—Ä–∏–∫–∏ –±–µ—Å–ø–æ–ª–µ–∑–µ–Ω —è. –Ø –¥–æ–ª–∂–µ–Ω –º–µ—Ç–∫–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–æ–µ–π –º–µ—Ç—Ä–∏–∫–∏. –Ø –¥–æ–ª–∂–µ–Ω –æ–±—É—á–∞—Ç—å —Ç–æ—á–Ω–µ–µ, —á–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—ã—Ç–∞–µ—Ç—Å—è –º–µ–Ω—è –æ–±–æ–π—Ç–∏. –Ø –¥–æ–ª–∂–µ–Ω –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –ª—É—á—à–µ –¥–æ —Ç–æ–≥–æ, –∫–∞–∫ –æ–Ω –æ–±—É—á–∏—Ç —Å–≤–æ—é. –ò —è —ç—Ç–æ —Å–¥–µ–ª–∞—é. –ö–ª—è–Ω—É—Å—å –ø–µ—Ä–µ–¥ —Ç–∏–º –ª–∏–¥–æ–º. –Ø –∏ –º–æ—è –º–µ—Ç—Ä–∏–∫–∞ ‚Äî –º—ã –∑–∞—â–∏—Ç–Ω–∏–∫–∏ –º–æ–µ–π –≥–∞–ª–µ—Ä—ã. –ú—ã –Ω–µ –±–æ–∏–º—Å—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤. –ú—ã —Å–ø–∞—Å–∏—Ç–µ–ª–∏ ROI –Ω–∞—à–µ–≥–æ –æ—Ç–¥–µ–ª–∞. –ü—É—Å—Ç—å –±—É–¥–µ—Ç —Ç–∞–∫. –ü–æ–∫–∞ –Ω–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –±–æ–ª—å—à–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏ –Ω–µ –Ω–∞—Å—Ç—É–ø–∏—Ç —ç–ø–æ—Ö–∞ AGI. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä.\n",
    "\n",
    "–ü–æ—á–µ–º—É —è –≤—ã–±—Ä–∞–ª —ç—Ç—É –º–µ—Ç—Ä–∏–∫—É:  \n",
    "<–†–ê–°–°–ö–ê–ó_–ü–†–û_–ú–ï–¢–†–ò–ö–£>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "239a5e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00],\n",
       "       [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00],\n",
       "       [-3.260e-02, -1.499e-01,  2.320e-02, ..., -2.370e-02, -2.610e-02,\n",
       "        -1.832e-01],\n",
       "       ...,\n",
       "       [ 7.530e-02, -3.280e-02,  1.960e-02, ...,  1.000e-04, -1.710e-02,\n",
       "         3.800e-03],\n",
       "       [ 2.260e-02,  5.610e-02,  3.730e-02, ..., -6.020e-02,  1.041e-01,\n",
       "         3.920e-01],\n",
       "       [ 1.692e-01,  6.980e-02, -1.120e-02, ...,  7.210e-02, -5.685e-01,\n",
       "        -2.003e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da42260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAverageNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepAverageNetwork, self).__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(embeddings_matrix))\n",
    "        self.embeddings_dim = embeddings_matrix.shape[-1]\n",
    "        self.fc1 = nn.Linear(self.embeddings_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.fc5 = nn.Linear(64, 3)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(self.embeddings_dim)\n",
    "\n",
    "        # self.sequential = nn.Sequential(\n",
    "        #     nn.\n",
    "\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        \n",
    "        x1 = self.fc1(x)\n",
    "        x1 = self.batchnorm1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        \n",
    "   \n",
    "        x2 = self.fc2(x1)\n",
    "        x2 = self.batchnorm1(x2)\n",
    "        x2 = self.relu(x2)\n",
    "     \n",
    "        x3 = self.fc3(x2)\n",
    "        x3 = self.batchnorm1(x3)\n",
    "        x3 = self.relu(x3)\n",
    "\n",
    "        x4 = self.fc4(x3+x2)\n",
    "        x4 = self.batchnorm1(x4)\n",
    "        x4 = self.relu(x4)\n",
    "        x4 = self.dropout(x4)\n",
    "\n",
    "        \n",
    "        x5 = self.fc5(x4+x1)\n",
    "        x5 = self.sigmoid(x5)\n",
    "       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7966f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepAverageNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b4a2161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepAverageNetwork(\n",
       "  (embeddings): Embedding(101, 300)\n",
       "  (fc1): Linear(in_features=300, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc5): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (batchnorm1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efad1d1",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42a8588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c552fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628847fe",
   "metadata": {},
   "source": [
    "## –°–¥–µ–ª–∞–π—Ç–µ —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc5b9ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 128 elements not 300",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m \u001b[39m# Do forward propagation to get the model's belief\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m logits \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, y\u001b[39m.\u001b[39mlong())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [49], line 23\u001b[0m, in \u001b[0;36mDeepAverageNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(x, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x)\n\u001b[0;32m---> 23\u001b[0m x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatchnorm1(x1)\n\u001b[1;32m     24\u001b[0m x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x1)\n\u001b[1;32m     26\u001b[0m x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x1)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 128 elements not 300"
     ]
    }
   ],
   "source": [
    "num_epochs = 2  # –ó–∞–¥–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Define the following variables to keep track of the running losses and accuracies\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        \n",
    "        print(i)\n",
    "        if i>2:\n",
    "            break\n",
    "        \n",
    "        # use gpu if necessary\n",
    "#         if gpu_available:\n",
    "#             X = X.cuda()\n",
    "#             y = y.cuda()\n",
    "        \n",
    "        # clear the gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Do forward propagation to get the model's belief\n",
    "        logits = model(X)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_fn(logits, y.long())\n",
    "        \n",
    "        # Run a backward propagation to get the gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the model's parameter\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get the model's prediction \n",
    "        pred = torch.argmax(logits,dim=1)\n",
    "        \n",
    "        # Update the running statistics\n",
    "        running_f1 += f1_score(y, pred, average='weighted')\n",
    "        running_loss += loss.item()\n",
    "        count += X.size(0)\n",
    "        \n",
    "    # print the running statistics after training for 100 epochs\n",
    "#     if (epoch + 1) % 100 == 0:\n",
    "#         print('Epoch [{} / {}] Average Training Accuracy: {:4f}'.format(epoch + 1, \\\n",
    "#                                                                         num_epochs, running_acc / count))\n",
    "#         print('Epoch [{} / {}] Average Training loss: {:4f}'.format(epoch + 1, \\\n",
    "#                                                                     num_epochs, running_loss / len(trainloader)))\n",
    "    \n",
    "    # train\n",
    "    ...\n",
    "\n",
    "    # validation\n",
    "    ...\n",
    "    \n",
    "# test\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744bc39c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634b9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 2  # –ó–∞–¥–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "\n",
    "...\n",
    "\n",
    "for n_epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # train\n",
    "    ...\n",
    "\n",
    "    # validation\n",
    "    ...\n",
    "    \n",
    "# test\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87583e79",
   "metadata": {},
   "source": [
    "# –í—ã–≤–æ–¥—ã\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ –Ω–µ–±–æ–ª—å—à–æ–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç–µ. –ß—Ç–æ —É–¥–∞–ª–æ—Å—å, –≤ —á–µ–º –Ω–µ —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad7f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
